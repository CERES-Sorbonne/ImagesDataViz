{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importation de modules\n",
    "\n",
    "import unicodedata as uni\n",
    "import re\n",
    "import os\n",
    "import csv as csvlib\n",
    "from fuzzywuzzy import fuzz\n",
    "from fuzzywuzzy import process\n",
    "import xml.etree.ElementTree as ET\n",
    "ns = \"http://www.tei-c.org/ns/1.0\"\n",
    "from itertools import combinations\n",
    "from tqdm.auto import tqdm\n",
    "from math import factorial\n",
    "from numpy import array, mean, percentile\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction pour supprimer les diacritiques\n",
    "\n",
    "def strip_accents(string):\n",
    "   return ''.join(c for c in uni.normalize('NFD', string)\n",
    "                  if uni.category(c) != 'Mn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables générales\n",
    "\n",
    "# définir la fourchette de caractères des phrases que l'on va comparer\n",
    "min_phr_len = 20\n",
    "max_phr_len = 2000\n",
    "\n",
    "# définir la distance de levenshtein minimale pour créer un lien\n",
    "min_lev_distance = 0.80"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extraire les phrases et créer les squelettes textuels\n",
    "\n",
    "# initier un compteur de phrases pour assigner des identifiants dans les noeuds\n",
    "id_phrase = 0\n",
    "# créer un dictionnaire nodes[id_text + \"ph\" + id_phrase] = [id_text, id_phrase, text, label]\n",
    "nodes = {}\n",
    "# créer un dictionnaire edges[source] = [target, edge_type, lev_distance]\n",
    "edges = {}\n",
    "\n",
    "for root_path, _, files in os.walk(\"mazarinades\"):\n",
    "    for name in files:\n",
    "        if(not name.endswith(\".xml\")):\n",
    "            continue\n",
    "        # pour chaque fichier .xml du dossier mazarinades\n",
    "        with open(os.path.join(root_path, name), 'r', encoding='utf-8') as f:\n",
    "            xml = f.read()\n",
    "            root = ET.fromstring(xml)\n",
    "            id_phrase = 0\n",
    "\n",
    "            # récupérer le titre du document pour l'afficher en label des noeuds\n",
    "            title = root.find(\".//{\" + ns + \"}title\").text\n",
    "            try:\n",
    "                label = re.sub(r'\\s+', ' ', title).replace('\\n', '')\n",
    "            except:\n",
    "                label = \"no_title\"\n",
    "\n",
    "            # récupérer l'identifiant dans id_text\n",
    "            id_text = name.replace(\".xml\", \"\")\n",
    "            # insérer le noeud titre dans le dictionnaire de noeuds\n",
    "            nodes[id_text + \"ph\" +\n",
    "                  str(id_phrase)] = [id_text, str(id_phrase), \"null\", label]\n",
    "\n",
    "            # extraire le texte et supprimer les balises, les espaces multiples, les tirets, les diacritiques et mettre tout en minuscules\n",
    "            full_text = re.sub(\n",
    "                r'\\s+', ' ', (re.sub(r'<.+?>|<\\/?|\\/?>', ' ', xml.split(\"body>\")[1])))\n",
    "            full_text = strip_accents(full_text.replace(\"¬\", \"\").lower())\n",
    "\n",
    "            # créer un noeud pour chaque phrase qui dépasse 20 caractères\n",
    "            phrases = re.findall(\"[^\\.\\?\\!]{\" + str(min_phr_len) + \",}\", full_text)\n",
    "            for phrase in phrases:\n",
    "                id_phrase += 1\n",
    "                nodes[id_text + \"ph\" + str(id_phrase)] = [id_text,\n",
    "                                                     id_phrase, phrase, \"null\"]\n",
    "                # créer un lien avec la phrase précédente\n",
    "                edges[id_text + \"ph\" +\n",
    "                      str(id_phrase - 1)] = [id_text + \"ph\" + str(id_phrase), \"precedence\", \"null\"]\n",
    "\n",
    "# vérifier le nombre de phrases\n",
    "print(len(nodes))\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Répartir les phrases dans des groupes\n",
    "\n",
    "# créer une liste de graduations pour les groupes de taille de phrase\n",
    "graduations = []\n",
    "\n",
    "# définir des graduations en fonction de la taille minimale, maximale et de l'écart de levenshtein minimal\n",
    "i = min_phr_len\n",
    "while i < max_phr_len:\n",
    "    graduations.append(round(i))\n",
    "    i = i/min_lev_distance\n",
    "graduations.append(max_phr_len)\n",
    "\n",
    "# répartir les noeuds dans des groupes qui couvrent 3 graduations\n",
    "groups = [[(id, node) for id, node in nodes.items()\n",
    "           if graduations[i] < len(node[2]) < graduations[i+2]]\n",
    "          for i in range(len(graduations)-2)]\n",
    "\n",
    "# attribuer à chaque phrase un indice entre 0 et 1, qui indique sa position entre les 2 bornes du groupe\n",
    "# ne comparer qu'avec les phrases qui ont un indice entre 0.25 plus grand et 0.25 plus petit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Créer les liens de proximité entre phrases\n",
    "\n",
    "# ajouter une barre de progression\n",
    "total_comb = sum(\n",
    "    [factorial(len(group)) // (2*factorial(len(group) - 2)) for group in groups])\n",
    "with tqdm(total=total_comb) as pbar:\n",
    "    # comparer les phrases de chaque groupe entre elles\n",
    "    for group in groups:\n",
    "        for (id1, node1), (id2, node2) in combinations(group, 2):\n",
    "            # si les phrases ne font pas partie du même texte\n",
    "            if node1[0] != node2[0]:\n",
    "                lev_distance = fuzz.ratio(node1[2], node2[2]) / 100\n",
    "                # créer des liens avec les phrases qui sont proches à 80%\n",
    "                if (lev_distance >= min_lev_distance):\n",
    "                    edges[id1] = [id2, \"proximity\", lev_distance]\n",
    "            pbar.update(1)\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3785a633635558c05a6b1aca16a69f0ae054170ee828414f8ee7977178feb401"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
